{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "310"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Necessary imports\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# path = \"nationa\"\n",
    "path_raw = \"national_raw/\"\n",
    "# path_processed = \"Data/processed/\"\n",
    "\n",
    "files = glob.glob(path_raw + \"*.csv\")\n",
    "#specify path to files.\n",
    "files\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_recent_data_format(temp, file, indicator, indicator_category, unit_of_measure):\n",
    "    \"\"\"One of the formats in the CSV's is the 'most recent data format' with just one \n",
    "    value (the most recent one known by UNAIDS), this function checks the number of columns.\n",
    "    Selects the columns to keep first 3. Then locs that dataframe, re-names a columns in place. \n",
    "    Finally calls the melt function to shape the file into the right format. It returns\n",
    "    the correctly shaped file to the loop which concats it to the rest.\n",
    "    \n",
    "    -- Input: \n",
    "    temp = a UNAIDS CSV file with the most recent format read in the for loop that loops throught the files. \n",
    "    file = the name of the file to check for bugs if the assert is trigged\n",
    "    indicator = the name of the indicator\n",
    "    indicator_category = the name of the key population \n",
    "    unit_of_measure = can be either a number or a percentage\n",
    "    \n",
    "    -- Output: \n",
    "    Returns a correctly formatted dataframe which can be concatted to the final dataframe. \n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        assert len(temp.columns) == 3 #Make sure there are just 3 columns so we don't lose any important information.\n",
    "    except:\n",
    "        print('There are more than 3 columns in iteration {} please check it out'.format(file))\n",
    "        print(temp.columns)\n",
    "        \n",
    "    columns_to_keep = temp.columns[0:2]\n",
    "    temp = temp.loc[:, tuple(columns_to_keep)] #ignore the irrelevant columns\n",
    "    temp.rename(columns={'Most recent data as of 2017': '2017'}, inplace=True)\n",
    "    \n",
    "    temp_final = melt(temp, indicator, indicator_category, unit_of_measure)\n",
    "    \n",
    "    return temp_final\n",
    "\n",
    "def multiple_years(temp, file, indicator, indicator_category, unit_of_measure):\n",
    "    \"\"\"The other format provided by UNAIDS is data from multiple years. Every year \n",
    "    has 3 values (upper, lower and realistic). Which yield years*3 columns + 1 for the country.\n",
    "    Then the columns per category are initiallized for get the right subset of the df at a later stage. \n",
    "    The for loop appends the correct columns to the columns_lists. \n",
    "    3 temp df are created by locing the right columns. Next the right keys (columns) are matched per dataset. \n",
    "    These were for instance 2012_lower and should be 2012, replacement is done in place. \n",
    "    Next all dataframes are melted into the right format and the estimate is added to the indicator category. \n",
    "    All files are concatted and finnaly returned to the for loop that loops over the folder. \n",
    "    \n",
    "    -- Input: \n",
    "    temp = a UNAIDS CSV file with the multiple years format read in the for loop that loops throught the files. \n",
    "    file = the name of the file to check for bugs if the assert is trigged\n",
    "    indicator = the name of the indicator\n",
    "    indicator_category = the name of the key population \n",
    "    unit_of_measure = can be either a number or a percentage\n",
    "    \n",
    "    -- Output: \n",
    "    Returns a correctly formatted dataframe which can be concatted to the final dataframe. \n",
    "    \"\"\"\n",
    "    temp.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "    \n",
    "    columns_lower = ['Country']\n",
    "    columns_upper = ['Country']\n",
    "    columns_realistic = ['Country']\n",
    "    #print(columns_lower)\n",
    "    for i in range(1, len(temp.columns)):\n",
    "        if 'upper' in list(temp.columns)[i]:\n",
    "            #print('upper', i)\n",
    "            columns_upper.append(list(temp.columns)[i])\n",
    "        elif 'lower' in list(temp.columns)[i]:\n",
    "            columns_lower.append(list(temp.columns)[i])\n",
    "            #print('lower', i)\n",
    "        elif 'upper' or 'lower' not in list(temp.columns)[i]:\n",
    "            columns_realistic.append(list(temp.columns)[i])\n",
    "            #print('years', i)\n",
    "\n",
    "    temp_realistic = temp.loc[:, tuple(columns_realistic)]\n",
    "    temp_lower = temp.loc[:, tuple(columns_lower)]\n",
    "    temp_upper = temp.loc[:, tuple(columns_upper)]\n",
    "\n",
    "    keys_lower = columns_lower\n",
    "    values_realistic = columns_realistic\n",
    "    dict_lower = dict(zip(keys_lower, values_realistic))\n",
    "    temp_lower.rename(columns=dict_lower, inplace=True)\n",
    "    \n",
    "    keys_upper = columns_upper\n",
    "    values_realistic = columns_realistic\n",
    "    dict_upper = dict(zip(keys_upper, values_realistic))\n",
    "    temp_upper.rename(columns=dict_upper, inplace=True)\n",
    "    \n",
    "#     temp_realistic = melt(temp_realistic, indicator, str(indicator_category)+' realistic estimate', unit_of_measure)\n",
    "    temp_realistic = melt(temp_realistic, indicator, str(indicator_category), unit_of_measure)\n",
    "    temp_lower = melt(temp_lower, indicator, str(indicator_category)+' lower bound', unit_of_measure)\n",
    "    temp_upper = melt(temp_upper, indicator, str(indicator_category)+' upper bound', unit_of_measure)\n",
    "    #print(temp_realistic.columns)\n",
    "    #print(temp_upper.columns)\n",
    "    #print(temp_lower.columns)\n",
    "    \n",
    "#     temp_final = pd.concat([temp_realistic, temp_lower, temp_upper])\n",
    "    temp_final = pd.concat([temp_realistic])\n",
    "                      \n",
    "    #return temp_realistic, temp_lower, temp_upper\n",
    "    return temp_final\n",
    "\n",
    "def melt(temp, indicator, indicator_category, unit_of_measure):\n",
    "    \"\"\"\n",
    "     -- Input: \n",
    "    temp = a UNAIDS CSV file with the multiple years format read in the for loop that loops throught the files. \n",
    "    file = the name of the file to check for bugs if the assert is trigged\n",
    "    indicator = the name of the indicator\n",
    "    indicator_category = the name of the key population \n",
    "    unit_of_measure = can be either a number or a percentage\n",
    "    \n",
    "    A function to melt all given dataframes in the right format.\n",
    "    -- Output:\n",
    "    Melted dataframe in the right format. \n",
    "         \"\"\"\n",
    "    #id_vars: define identifier variables\n",
    "    identifiers = \"Country\"\n",
    "    #var_name: scalar; now distributed in multiple columns, will be one column\n",
    "    scalar = 'date_value'\n",
    "    #value_name: the values that are in the columns of the scalar get their own column\n",
    "    valuename = 'measure_value'\n",
    "    \n",
    "    temp = pd.melt(temp, id_vars = identifiers, var_name=scalar, value_name = valuename)\n",
    "    temp['indicator_category'] = indicator_category\n",
    "    temp['indicator'] = indicator\n",
    "    temp['unit_of_measure'] = unit_of_measure\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop over all files and execute steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"The cell to get all files in the right format. It loops over a specified files folder.\n",
    "A some variables are deducted from the file_name, then they are shaped into the right format\n",
    "by the specified helper functions. Finally all files are concated into a final total dataframe.\n",
    "\"\"\"\n",
    "\n",
    "df = pd.DataFrame(columns = ['Country', 'date_value', 'measure_value', \n",
    "                             'indicator_category', 'indicator', 'unit_of_measure'])\n",
    "\n",
    "\n",
    "for file in range(0, len(files)):\n",
    "    try:\n",
    "        file_name = files[file].split('\\\\')[-1]\n",
    "        assert len(file_name.split('_')) == 3 #Make sure all files are seperated by 3 _'s. \n",
    "        #print(file_name,' is not seperated correctly')\n",
    "    except:\n",
    "        print(file_name,' is not seperated correctly, please check it out')\n",
    "\n",
    "    indicator_category = file_name.split(\"_\")[2]\n",
    "    indicator_category = indicator_category.split('.')[0]\n",
    "\n",
    "    indicator = file_name.split(\"_\")[0]\n",
    "\n",
    "    unit_of_measure = file_name.split(\"_\")[1]\n",
    "\n",
    "    #Import the file\n",
    "    temp = pd.read_csv(files[file])\n",
    "\n",
    "    # Select the right format, first is 'Most recent format'\n",
    "    # Select the right year if another (i.e. 2018) is applicable. \n",
    "    if \"Most recent data as of 2017\" in list(temp.columns):\n",
    "        temp = most_recent_data_format(temp, file, indicator, indicator_category, unit_of_measure)\n",
    "    #Select the multiple year format.\n",
    "    else:\n",
    "        try:\n",
    "            temp = multiple_years(temp, file, indicator, indicator_category, unit_of_measure)\n",
    "        except:\n",
    "            print(file_name)\n",
    "    df = pd.concat([df, temp])\n",
    "#     print(file_name, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the file for syntax mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['indicator'] = df['indicator'].str.replace('  ',' ').str.lstrip().str.rstrip()\n",
    "\n",
    "\"\"\"Regex to keep only integers and floats\"\"\"\n",
    "non_decimal = re.compile(r'[^\\d.]+')\n",
    "df['measure_value'] = df['measure_value'].apply(lambda x: non_decimal.sub('',x) if type(x) == str else x)\n",
    "\n",
    "\"\"\"Convert all to numeric values\"\"\"\n",
    "df['measure_value'] = pd.to_numeric(df['measure_value'],errors='coerce')\n",
    "\n",
    "\"\"\"Drop all rows where measure value contains nans\"\"\"\n",
    "df = df[np.isfinite(df['measure_value'])]\n",
    "\n",
    "\"\"\"Double check if measure value only contains numeric values. Errors are printed\"\"\"\n",
    "for number in df['measure_value']:\n",
    "    try:\n",
    "        int(number)\n",
    "    except Exception:\n",
    "        print(number)       \n",
    "        \n",
    "        \n",
    "#remove whitespaces\n",
    "df['indicator_category'] = df['indicator_category'].str.replace('  ',' ').str.lstrip().str.rstrip()\n",
    "\n",
    "df.loc[:, 'indicator'] = df.indicator.str.replace('Prevalence', 'prevalence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the fil for typo's and add codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Read csv with countries and isocodes\"\"\"\n",
    "# general_dir = \"/home/science/Projects/aidsfonds/3_unaidsupdate_Mei_2018/Data/\"\n",
    "countries = pd.read_csv('region_codes.csv',encoding = \"ISO-8859-1\", delimiter = ';')\n",
    "\n",
    "\"\"\"Create dictionary with country as key and ISO as value\"\"\"\n",
    "isocodes = countries[['Name','ISO3']].set_index('Name')\n",
    "isocodes = isocodes.to_dict(orient='dict')\n",
    "isocodes = isocodes['ISO3'].items()\n",
    "isocodes = dict(isocodes)\n",
    "\n",
    "\"\"\"Create dictionary with to replace the wrong matches\"\"\"\n",
    "nadict = {}\n",
    "# nadict['Czech Republic'] = 'Czechia'\n",
    "nadict[\"Democratic People\\'s Republic of Korea\"] = \"North korea\"\n",
    "nadict[\"Democratic Republic of the Congo\"] = \"Republic of congo\"\n",
    "# nadict[\"Korea (Republic of)\"] = \"South korea\"\n",
    "# nadict[\"Korea (Democratic People's Republic of)\"] = \"North korea\"\n",
    "nadict[\"Congo\"] = \"Republic of congo\"\n",
    "nadict[\"Republic of Korea\"] = \"South korea\"\n",
    "nadict['Republic of Moldova'] = \"Moldova\"\n",
    "nadict['Swaziland'] = \"Eswatini\"\n",
    "nadict['The former Yugoslav Republic of Macedonia'] = \"Macedonia\"\n",
    "nadict['United Kingdom'] = \"United Kingdom of Great Britain and Northern Ireland\"\n",
    "nadict['United Republic of Tanzania'] = \"Tanzania\"\n",
    "nadict['United States'] = \"United States of America\"\n",
    "nadict['United States Virgin Islands'] = \"Virgin Islands (U.S.)\"\n",
    "nadict['Global'] = 'Global'\n",
    "nadict['Viet Nam'] = 'Vietnam'\n",
    "nadict[\"CÃ´te d'Ivoire\"] = 'Ivory coast'\n",
    "nadict[\"North Macedonia\"] = 'Macedonia'\n",
    "nadict[\"Czechia\"] = 'Czech Republic'\n",
    "nadict[\"Tanzania, United Republic of\"] = 'United Republic of Tanzania'\n",
    "\n",
    "\n",
    "\"\"\"Replace wrong country name with right country name\"\"\"\n",
    "df = df.replace(nadict)\n",
    "\n",
    "\"\"\"Delete Global country name, can not be mapped in Zoom\"\"\"\n",
    "df = df[df['Country'] != 'Global']\n",
    "\n",
    "\"\"\"Create new column with ISO3-codes\"\"\"\n",
    "df['ISO'] = df['Country'].map(isocodes)\n",
    "\n",
    "\n",
    "# df['Country'] = df['Country'].replace(\"Tanzania, United Republic of\", \"United Republic of Tanzania\")\n",
    "\n",
    "\"\"\"Create new column with ISO3-codes\"\"\"\n",
    "df['ISO'] = df['Country'].str.lower().map(isocodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter relevant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rid of all values that are not just years\n",
    "years = ['1990', '1991', '1992', '1993', '1994', '1995', '1996', '1997', '1998', '1999', '2000', '2001', '2002',\n",
    " '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015',\n",
    " '2016', '2017', '2018']\n",
    "\n",
    "df = df[df['date_value'].isin(years)].reset_index()\n",
    "del df['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [['Country', 'Date', 'measure_value', 'legend', 'Indicator', 'Value_format', 'ISO']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('unaids_national_25-08-2020.csv', sep=',', encoding = 'UTF-8', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
